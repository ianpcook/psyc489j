<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

Simulation Methods
========================================================
author: Jeffrey Chrabaszcz
date: 14 January 2014
transition: none

```{r setup, include=FALSE, echo=FALSE}
require(knitr)
require(ggplot2)
opts_chunk$set(include=TRUE,cache=TRUE,fig.align='center')
options(digits = 3)
```

Outline
========================================================

1. Pseudo-random numbers
2. Permutation tests
3. Cross-validation
4. Bootstrapping
5. Modeling parameter uncertainty
6. Build a better t-test

Pseudo-random numbers
========================================================

We can get nearly random numbers with [atmospheric noise](http://www.random.org) and [cesium atomic decay](http://www.fourmilab.ch/hotbits/).

We can get pseudo-random numbers from computers. Pseudorandom algorithms are excellent at drawing uniform numbers.

```{r runif_block}
set.seed(42)
runif(10)
```

Random is defined by context
========================================================

```{r plotting_runif,fig.height=6,fig.width=12}
set.seed(42)
a <- runif(10000)
qplot(a, binwidth = .01) + theme_bw(base_size = 24) + xlim(c(-.5, 1.5)) + ylim(c(0, 200))
```

Accept-reject methods
========================================================

One old and slow method for generating desirable distributions is the accept-reject method. This is not what your computer is doing, but it's a reasonable approximation that we can use for demonstration.

We require only a way of determining relative heights of a function,[f(x)], and a method of drawin uniformly-distributed numbers.

1. Generate a candidate x value.
2. Generate a corresponding y value.
3. Reject if y > f(x), otherwise keep.
4. Repeat many times.

Accept-reject code
========================================================

This code runs an accept-reject algorithm to determine a unit normal over a specified range.

```{r ar_code}
acceptReject <- function(lb, ub, fx) {
  x <- runif(1) * (ub - lb) + lb
  y <- runif(1)
  out <- ifelse(y > fx(x), NA, y)
  return(c(x, out))
}
```

Using  the function
========================================================

We have some options for iterating in R. We need to run that accept-reject function a large number of times to get a good idea of our target distribution. One way involves explicit loops:

```{r}
n <- 10000
loop.df <- data.frame(x = rep(NA, n), y = rep(NA, n))
for (i in 1:n) {
  temp <- acceptReject(-5, 5, dnorm)
  loop.df$x[i] <- temp[1]
  loop.df$y[i] <- temp[2]
}
```

Using the function
========================================================

Alternately, we could use the faster/more convenient **replicate**.

```{r}
b <- replicate(10000, acceptReject(-5, 5, dnorm))
df <- as.data.frame(t(b))
names(df) <- c("x", "y")
```

Plotted results
========================================================

```{r ar_results,fig.height=8,fig.width=10}
qplot(x, y, data = df) + theme_bw(base_size = 24)
```

Sample function
========================================================

The **sample** function in R is a useful way to randomly sample objects in a finite set.

```{r sample_ex}
sample(c("heads", "tails"), 10, replace = TRUE)
```

There are many uses of sample, (not just sampling coin flips), but this is one application.

Permutation tests
========================================================

We can use simulations to side-step some of the assumptions of NHST and multiple regression. Permutation tests do not assume normality of errors. As a result, they are robust to **skewness** and **outliers**, two plagues of traditional statistics.

1. Choose test
2. Perform test as norm to derive test statistic, (ignore p value)
3. Randomly order predictor, perform test using re-ordered predictor
4. Repeat 3 many times
5. Determine probability of obtaining test as large or larger than result of step 2.

Permutation example
========================================================

```{r}
data(sleep)
permTest <- function(df) {
  df$x <- sample(df$x, length(df$x))
  return(t.test(y ~ x, data = df)$statistic)
}

n <- 1000
t.real <- t.test(sleep$extra ~ sleep$group)$statistic
ts <- replicate(n, permTest(data.frame(x = sleep$group, y = sleep$extra)))
sum(abs(ts) > abs(t.real))/n
```

Split-half cross-validation
========================================================

A cheap alternative to some problems otherwise solved by external validation, this is the simplest variant of cross-validation techniques.

```{r cross_val_code}
data(diamonds)
select.data <- sample(1:nrow(diamonds), nrow(diamonds)/2)
my.lm <- lm(price ~ carat * clarity * x * y * z, data = diamonds[select.data,])
cross.val <- predict(my.lm, diamonds[-select.data,], type = "response")
```

Using cross-validation
========================================================

```{r cross_val_output}
c(sd(diamonds$price[select.data]), sd(residuals(my.lm)))
c(sd(diamonds$price[-select.data]), sd(diamonds$price[-select.data] - cross.val))
```

Bootstrap
========================================================

Treat the sample as a "population," repeatedly sample cases with replacement and fit models.
Creates an empirical 95% CI.

```{r boot_setup}
bootS <- function(model.formula, df) {
  new.df <- df[sample(nrow(df), nrow(df), replace = TRUE),]
  mod <- lm(model.formula, data = new.df)
  return(coef(mod))
}

df <- read.csv("data/ravensdata.csv")
b <- t(replicate(1000, bootS(ravens ~ shape * nfc, df)))
```

Bootstrap output
========================================================

```{r boot_out}
apply(b, 2, FUN = quantile, probs = c(.025, .975))
```

```{r boot_graph,echo=FALSE,fig.height=6,fig.width=16}
library(reshape2)
qplot(value, data = melt(as.data.frame(b))) + facet_grid(~variable, scale = "free_x") + geom_vline(xintercept = 0, color = "firebrick")+ theme_bw(base_size = 24)
```

Modeling parameter uncertainty
========================================================

A subtly different approach is to simulate random draws from the distributions defined by your coefficients and coefficent standard errors.

```{r sim_block}
library(arm)
my.lm <- lm(ravens ~ nfc, data = df)
my.sim <- sim(my.lm, n.sims = 50)
str(my.sim)
```

Graphing sim output
========================================================

```{r sim_graph,fig.height=6,fig.width=10}
coefs <- as.data.frame(my.sim@coef)
names(coefs)[1] <- "Intercept"
ggplot(df, aes(nfc, ravens)) + geom_abline(data = coefs, aes(intercept = Intercept, slope = nfc), color = "grey") + geom_point() + theme_bw(base_size = 24)
```

Build a better t-test
========================================================

```{r,include=FALSE}
library(rstan)
sdat <- list(
  Ny = sum(sleep$group == "1"),
  Nx = sum(sleep$group == "2"),
  y = sleep$extra[sleep$group == "1"],
  x = sleep$extra[sleep$group == "2"]
)

smod <- "
data {
  int<lower=1> Ny;
  int<lower=1> Nx;
  vector[Ny] y;
  vector[Nx] x;
}
parameters {
  real mu_y;
  real mu_x;
  real<lower=0> sigma_y;
  real<lower=0> sigma_x;
  real<lower=1> nu;
}
transformed parameters {
  real muDiff;
  real sigmaDiff;
  real effSize;

  muDiff <- mu_y - mu_x;
  sigmaDiff <- sigma_y - sigma_x;
  effSize <- (mu_y - mu_x) / sqrt(((Ny - 1) * sigma_y ^ 2 + (Nx - 1) * sigma_x ^ 2) / (Ny + Nx));
}
model {
  mu_y ~ normal(0, 10);
  mu_x ~ normal(0, 10);
  sigma_y ~ inv_chi_square(2);
  sigma_x ~ inv_chi_square(2);
  nu ~ uniform(1, 100);
  y ~ student_t(nu, mu_y, sigma_y);
  x ~ student_t(nu, mu_x, sigma_x);
}
"

fit <- stan(model_code = smod, data = sdat, refresh = -1)
```

We can use Stan to do things that aren't specifically linear models.

```
sdat <- list(
  Ny = sum(sleep$group == "1"),
  Nx = sum(sleep$group == "2"),
  y = sleep$extra[sleep$group == "1"],
  x = sleep$extra[sleep$group == "2"]
)

data {
  int<lower=1> Ny;
  int<lower=1> Nx;
  vector[Ny] y;
  vector[Nx] x;
}
```

Parameters
========================================================

```
parameters {
  real mu_y;
  real mu_x;
  real<lower=0> sigma_y;
  real<lower=0> sigma_x;
  real<lower=1> nu;
}
transformed parameters {
  real muDiff;
  real sigmaDiff;
  real effSize;
  muDiff <- mu_y - mu_x;
  sigmaDiff <- sigma_y - sigma_x;
  effSize <- (mu_y - mu_x) / sqrt(((Ny - 1) * sigma_y ^ 2 + (Nx - 1) * sigma_x ^ 2) / (Ny + Nx));
}
```

Modeling statements
========================================================

```
model {
  mu_y ~ normal(0, 10);
  mu_x ~ normal(0, 10);
  sigma_y ~ inv_chi_square(2);
  sigma_x ~ inv_chi_square(2);
  nu ~ uniform(1, 100);
  y ~ student_t(nu, mu_y, sigma_y);
  x ~ student_t(nu, mu_x, sigma_x);
}
```

Output
========================================================

<pre><code style="font-size:20pt">
```{r,echo=FALSE}
print(fit, probs = c(.025, .975))
```
</code></pre>

When does this matter?
========================================================

```
model 1 {
  tau ~ inv_chi_square(1);
  mu ~ normal(0,100);
  for (l in 1:L)
    beta[l] ~ normal(mu,sigma);
  for (n in 1:N)
      y[n] ~ normal(x[n] * beta[pair[n]], tau);
}
model 2 {
  tau ~ inv_chi_square(1);
  mu ~ normal(0,100);
  for (l in 1:L)
    beta[l] ~ normal(mu,sigma);
  for (n in 1:N)
      y[n] ~ normal(x[n] * beta[pair[n]], tau[report[n]]);
}
```
